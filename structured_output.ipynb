{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "773dae67",
   "metadata": {},
   "source": [
    "## Structured Outputs\n",
    "\n",
    "This Jupyter notebook shows examples of structured outputs with the GWDG SAIA API.\n",
    "\n",
    "[Source](https://docs.vllm.ai/en/latest/features/structured_outputs.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110f7a80",
   "metadata": {},
   "source": [
    "#### Prequesites\n",
    "1. To install the required packages remove the comment character before the next line\n",
    "2. Add your API Key to a .env file in the root directory (see .env.example file). \n",
    "3. Load the API key from the .env file (see the lines below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45acf138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "419142a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5329de97",
   "metadata": {},
   "source": [
    "#### Configure Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a775579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "base_url = \"https://chat-ai.academiccloud.de/v1\"\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=base_url,\n",
    "    api_key=api_key,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f58c3d",
   "metadata": {},
   "source": [
    "#### Get Model List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3d4dd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: meta-llama-3.1-8b-instruct, ['text'] -> ['text']\n",
      "1: openai-gpt-oss-120b, ['text'] -> ['text']\n",
      "2: gemma-3-27b-it, ['text', 'image'] -> ['text']\n",
      "3: qwen3-32b, ['text'] -> ['text', 'thought']\n",
      "4: qwen3-235b-a22b, ['text'] -> ['text', 'thought']\n",
      "5: llama-3.3-70b-instruct, ['text'] -> ['text']\n",
      "6: qwen2.5-vl-72b-instruct, ['text', 'image', 'video'] -> ['text']\n",
      "7: medgemma-27b-it, ['text', 'image'] -> ['text']\n",
      "8: qwq-32b, ['text'] -> ['text', 'thought']\n",
      "9: deepseek-r1, ['text'] -> ['text', 'thought']\n",
      "10: deepseek-r1-distill-llama-70b, ['text'] -> ['text', 'thought']\n",
      "11: mistral-large-instruct, ['text'] -> ['text']\n",
      "12: qwen2.5-coder-32b-instruct, ['text'] -> ['text']\n",
      "13: internvl2.5-8b, ['text', 'image'] -> ['text']\n",
      "14: teuken-7b-instruct-research, ['text'] -> ['text']\n",
      "15: codestral-22b, ['text'] -> ['text']\n",
      "16: llama-3.1-sauerkrautlm-70b-instruct, ['text', 'arcana'] -> ['text']\n",
      "17: meta-llama-3.1-8b-rag, ['text', 'arcana'] -> ['text']\n"
     ]
    }
   ],
   "source": [
    "models = client.models.list()\n",
    "\n",
    "for i, model in enumerate(models.model_dump()[\"data\"]):\n",
    "    print(f\"{i}: {model['id']}, {model['input']} -> {model['output']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a5ff2b",
   "metadata": {},
   "source": [
    "#### Structured Output from `guided_choice`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16dd2dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "model = client.models.list().data[0].id\n",
    "\n",
    "completion = client.chat.completions.create( \n",
    "    model=model, \n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"Classify this sentiment: Chat AI is wonderful!\"\n",
    "            } \n",
    "    ],\n",
    "    extra_body={\"guided_choice\": [\"positive\", \"negative\"]}, \n",
    "    ) \n",
    "\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024eb9c6",
   "metadata": {},
   "source": [
    "#### Structured Output with `guided_regex`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5629abd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alan_turing@enigma.com\n"
     ]
    }
   ],
   "source": [
    "model = client.models.list().data[5].id\n",
    "\n",
    "completion = client.chat.completions.create( \n",
    "    model=model, \n",
    "    messages=[ \n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"Generate an example email address for Alan Turing, who works in Enigma. End in .com and new line. Example result: alan.turing@enigma.com\\n\",\n",
    "            } \n",
    "    ], \n",
    "    extra_body={\"guided_regex\": r\"\\w+@\\w+\\.com\\n\", \"stop\": [\"\\n\"]}, \n",
    ") \n",
    "\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a03bd56",
   "metadata": {},
   "source": [
    "#### Structured Output as `json_schema`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "918e88b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Eleanor Vance\",\n",
      "  \"age\": 32\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "model = client.models.list().data[2].id\n",
    "\n",
    "class People(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "\n",
    "completion = client.chat.completions.create( \n",
    "    model=model, \n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"Generate a JSON with the name and age of one random person.\",\n",
    "        }\n",
    "    ], \n",
    "    response_format={\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"people\",\n",
    "            \"schema\": People.model_json_schema()\n",
    "        },\n",
    "    }, \n",
    ") \n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54a3dca",
   "metadata": {},
   "source": [
    "#### Optional: With Reasoning Outputs (if Reasoning Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a674719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reasoning_content:  None\n"
     ]
    }
   ],
   "source": [
    "print(\"reasoning_content: \", completion.choices[0].message.reasoning_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dab529",
   "metadata": {},
   "source": [
    "#### Optional: With JSON Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6525ed9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Eleanor Vance\",\n",
      "  \"age\": 32\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    People.model_validate_json(completion.choices[0].message.content)\n",
    "    print(completion.choices[0].message.content)\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ JSON error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "64-869 Python3 (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
